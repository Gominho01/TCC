{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b3be0a",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302cf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights, VGG19_Weights, ResNet50_Weights, ResNet152_Weights, DenseNet201_Weights, Inception_V3_Weights, MobileNet_V2_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcdce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando o dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Usando o dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49171b95",
   "metadata": {},
   "source": [
    "# **Transformando Imagens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd54362",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_224 = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "preprocess_299 = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19ff66",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198a1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        \n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        \n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "        \n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        return self.final_conv(dec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20380791",
   "metadata": {},
   "source": [
    "# **Classes e hiperparâmetros globais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035d519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema',\n",
    "               'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "               'Cardiomegaly', 'Nodule', 'Hernia', 'Mass', 'No Finding']\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c834f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'D:/Users/Lucas/Downloads/Outra Pasta/'\n",
    "metadata_df = pd.read_csv(base_path + 'Data_Entry_2017.csv')\n",
    "def load_image_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        image_list = file.read().splitlines()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9648f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 1,\n",
    "    'dropout_rate': 0.5,\n",
    "    'weight_decay': 1e-4,\n",
    "    'momentum': 0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ec9fe",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "993fe304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_multilabel(model, val_loader, device, num_classes):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    outputs_flat = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            outputs_flat.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, outputs_flat, average='macro')\n",
    "    log_loss_value = log_loss(y_true, outputs_flat)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Precision: {precision}, Recall: {recall}, F1-Score: {f1}, ROC AUC: {roc_auc}, Log Loss: {log_loss_value}, Accuracy: {accuracy}')\n",
    "    \n",
    "    return {'precision': precision, 'recall': recall, 'f1_score': f1, 'roc_auc': roc_auc, 'log_loss': log_loss_value, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f4e7d",
   "metadata": {},
   "source": [
    "# Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8a2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f'Época {epoch+1}/{num_epochs}', unit='batch')\n",
    "\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        loss_history.append(epoch_loss)\n",
    "        print(f'Época {epoch+1}, Loss: {epoch_loss}')\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f03309",
   "metadata": {},
   "source": [
    "# **Classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6ef389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, image_list, dataframe, img_dir, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, 'images', img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels_str = self.dataframe.loc[self.dataframe['Image Index'] == img_name, 'Finding Labels'].values[0]\n",
    "        labels_list = labels_str.split('|')\n",
    "\n",
    "        label_indices = [class_names.index(label) for label in labels_list]\n",
    "\n",
    "        labels = torch.zeros(num_classes)\n",
    "        if label_indices:\n",
    "            labels[label_indices] = 1.0\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5275c0",
   "metadata": {},
   "source": [
    "# Variaveis Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d78945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(image_list_path, dataframe, img_dir, batch_size, transform):\n",
    "    image_list = load_image_list(image_list_path)\n",
    "    train_list, val_list = train_test_split(image_list, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = ChestXrayDataset(train_list, dataframe, img_dir, transform)\n",
    "    val_dataset = ChestXrayDataset(val_list, dataframe, img_dir, transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a0c25",
   "metadata": {},
   "source": [
    "# **Modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c7f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, num_classes, pretrained=True):\n",
    "    model = None\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif model_name == 'vgg19':\n",
    "        model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'inception_v3':\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1 if pretrained else None, aux_logits=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif model_name == 'densenet201':\n",
    "        model = models.densenet201(weights=models.DenseNet201_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    elif model_name == 'resnet152':\n",
    "        model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'resnet_v2':\n",
    "        model = timm.create_model('resnetv2_50x1_bitm_in21k', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'nasnet':\n",
    "        model = timm.create_model('nasnetalarge', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'xception':\n",
    "        model = timm.create_model('xception', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'unet':\n",
    "        model = UNet(in_channels=3, out_channels=num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Modelo não suportado!\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147add3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo: vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 1/1: 100%|██████████| 1082/1082 [1:34:27<00:00,  5.24s/batch, loss=0.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Loss: 0.199841972461139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.048869820839788664, Recall: 0.040851431228000265, F1-Score: 0.0445023242353537, ROC AUC: 0.6681253962865958, Log Loss: 28.01405626698493, Accuracy: 0.3554464027737648\n",
      "Treinando o modelo: vgg19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 1/1: 100%|██████████| 1082/1082 [1:30:42<00:00,  5.03s/batch, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Loss: 0.20554015398466213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0, Recall: 0.0, F1-Score: 0.0, ROC AUC: 0.5140882185305047, Log Loss: 23.59329906193215, Accuracy: 0.0\n",
      "Treinando o modelo: resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 1/1: 100%|██████████| 1082/1082 [1:21:40<00:00,  4.53s/batch, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Loss: 0.1879399486175306\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'vgg16', 'vgg19', 'resnet50', 'resnet152', 'resnet50v2', \n",
    "    'inception_v3', 'mobilenet_v2', 'densenet201', 'nasnet', \n",
    "    'xception', 'unet'\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f'Treinando o modelo: {model_name}')\n",
    "    transform = preprocess_299 if model_name in ['inception_v3', 'nasnet', 'xception'] else preprocess_224\n",
    "    \n",
    "    train_loader, val_loader = create_dataloaders(base_path + 'train_val_list.txt', metadata_df, base_path, hyperparams['batch_size'], transform)\n",
    "    model = load_model(model_name, num_classes)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'], weight_decay=hyperparams['weight_decay'])\n",
    "\n",
    "    train_model(model, train_loader, val_loader, optimizer, criterion, hyperparams['num_epochs'], device)\n",
    "    metrics = evaluate_model_multilabel(model, val_loader, device, num_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
